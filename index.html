<!DOCTYPE HTML>
<html lang="bn">
<head>
  <meta charset="UTF-8">
  <title>Yasiru Ranasinghe</title>
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images2/profile/sloth.png">
</head>

<body>
  <table style="width:100%;max-width:800px;margin:auto;border:0;border-spacing:0;">
    <tr>
      <td>
        <table style="width:100%;margin:auto;border:0;border-spacing:0;">
          <tr>
            <td style="padding:2.5%;width:63%;vertical-align:middle;">
              <h1 style="text-align:center">Yasiru Ranasinghe</h1>
              <!-- <p>
                I am a 3<sup>rd</sup> year Ph.D. candidate at <a href="https://engineering.jhu.edu/vpatel36/">Vision & Image Understanding Lab</a>, 
                <a href="https://www.jhu.edu/">Johns Hopkins University</a> under the supervision of 
                <a href="https://scholar.google.com/citations?user=AkEXTbIAAAAJ&hl=en">Dr. Vishal M. Patel</a>. My research focuses on computer vision and its application on crowd analysis, object localization, and representation learning.
              </p> -->

              <p>
                I am a 4<sup>th</sup> year Ph.D. student at the 
                <a href="https://engineering.jhu.edu/vpatel36/">Vision & Image Understanding Lab</a>, 
                <a href="https://www.jhu.edu/">Johns Hopkins University</a>, 
                advised by <a href="https://scholar.google.com/citations?user=AkEXTbIAAAAJ&hl=en">Dr. Vishal M. Patel</a>.
                My research focuses on scene understanding, object detection, self-supervised learning, and leveraging foundation models for agent-based AI. 
                I am currently spending the summer as a research intern at <strong>Apple</strong>.
                </p>


              <!-- <p>
                I worked as a research assistant for <a href="http://covid.eng.pdn.ac.lk/research.php">AI4COVID</a> under 
                <a href="https://scholar.google.com/citations?user=yqup6Q8AAAAJ&hl=en">Prof. Janaka Ekanayake</a>, funded by 
                <a href="https://covidsouth.ai/">IDRC</a>. During my undergrad at <a href="https://web2.ee.pdn.ac.lk/">University of Peradeniya</a>, Sri Lanka, I worked on computer vision applications on spectral imagery and remote sensing under 
                <a href="https://scholar.google.com/citations?user=6_XOJbsAAAAJ&hl=en">Prof. Roshan Godaliyadda</a>, 
                <a href="https://scholar.google.com/citations?user=f5h5ByUAAAAJ&hl=en">Prof. Vijitha Herath</a>, and 
                <a href="https://scholar.google.com/citations?user=uJvb7zwAAAAJ&hl=en">Prof. Parakrama Ekanayake</a>.
              </p> -->
<p style="text-align:center">
  <a href="mailto:dranasi1@jhu.edu">Email</a> &nbsp;/&nbsp;
  <a href="https://scholar.google.com/citations?hl=en&user=sG77m5UAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
  <a href="https://www.linkedin.com/in/yasiruranasinghe/">LinkedIn</a>             
</p>

<p class="blink">Actively looking for Fall 2025 internship opportunities!</p>


            </td>
            <td style="padding:2.5%;width:40%;max-width:40%;">
              <a href="images2/profile/prof_image2.jpg">
                <img src="images2/profile/prof_image2.jpg" alt="Profile Photo" style="width:100%;max-width:100%;">
              </a>
            </td>
          </tr>
        </table>

        <hr>

        <table style="width:100%;margin:auto;border:0;border-spacing:0;">
          <tr>
            <td style="padding:10px;">
              <h2>Research</h2>
              <p>
  My research focuses on advancing visual scene understanding through object detection, self-supervised learning, and the use of foundation models. I am particularly interested in building vision systems that generalize across tasks and environments, with an emphasis on integrating foundation models into agent-based AI for perception.
</p>

            </td>
          </tr>
        </table>

        <hr>

<h2>News</h2>
<ul style="list-style-type:none; padding-left:0;">

  <li><strong>2025</strong>
    <ul>
      <li>May: Started summer internship at <strong>Apple</strong>.</li>
      <li>May: One paper accepted at <strong>AVSS'25</strong>.</li>
      <li>February: One paper accepted at <strong>CVPR'25</strong>.</li>
    </ul>
  </li>

  <li><strong>2024</strong>
    <ul>
      <li>March: One paper accepted at <strong>IEEE FG'24</strong>.</li>
      <li>February: Two papers accepted at <strong>CVPR'24</strong>.</li>
    </ul>
  </li>

  <li>
    <button onclick="toggleYear('news2023')" 
            style="all: unset; color:#007bff; cursor:pointer; font-weight:bold;">2023</button>
    <ul id="news2023" style="display:none;">
      <li>May: One paper accepted by <strong>JFST</strong>.</li>
    </ul>
  </li>

  <li>
    <button onclick="toggleYear('news2022')" 
            style="all: unset; color:#007bff; cursor:pointer; font-weight:bold;">2022</button>
    <ul id="news2022" style="display:none;">
      <li>September: Joined as a PhD student at <strong>Johns Hopkins University</strong>.</li>
      <li>January: One paper accepted by <strong>IEEE Access</strong>.</li>
    </ul>
  </li>

  <li>
    <button onclick="toggleYear('news2021')" 
            style="all: unset; color:#007bff; cursor:pointer; font-weight:bold;">2021</button>
    <ul id="news2021" style="display:none;">
      <li>December: One paper accepted by <strong>IEEE JSTARS</strong>.</li>
    </ul>
  </li>

</ul>

<script>
  function toggleYear(id) {
    const section = document.getElementById(id);
    section.style.display = (section.style.display === "none") ? "block" : "none";
  }
</script>


        <hr>
<h2>Publication List</h2>
<h2 onclick="toggleSection('cvprList')" style="cursor:pointer;">CVPR</h2>
<div id="cvprList" style="display:block;">
  <table style="width:100%;border-spacing:0;" cellpadding="20">
        <!-- SINR -->
                <!-- SINR -->
        <tr onmouseout="ff7_stop()" onmouseover="ff7_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                <div class="two" id='ff7_image'>
                    <img src='images2/sinr/main.png' height="120" width="160" alt="SINR main figure">
                </div>
                <img src='images2/sinr/results.png' height="100" width="160" alt="SINR pipeline">
                </div>
                <script type="text/javascript">
                function ff7_start() {
                    document.getElementById('ff7_image').style.opacity = "1";
                }
                function ff7_stop() {
                    document.getElementById('ff7_image').style.opacity = "0";
                }
                ff7_stop()
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <p>
                <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Jayasundara_SINR_Sparsity_Driven_Compressed_Implicit_Neural_Representations_CVPR_2025_paper.html" target="_blank">
                    <papertitle><em>SINR</em>: Sparsity Driven Compressed Implicit Neural Representations</papertitle>
                </a>
                </p>
                <p>
                Authors: Dhananjaya Jayasundara, Sudarshan Rajagopalan, <strong>Yasiru Ranasinghe</strong>, Trac D. Tran, and Vishal M. Patel
                </p>
                <em>CVPR</em>, 2025 &nbsp;<br>
                <p>
                This work presents a novel compression approach for implicit neural representations (INRs) by encoding their weight space using a sparse high-dimensional dictionary. Unlike prior INR compression methods, <em>SINR</em> avoids transmitting learned dictionaries and remains compatible with existing INR frameworks. It achieves significant storage savings while preserving reconstruction quality across diverse signal types including images, occupancy fields, and NeRFs.
                </p>
            </td>
            </tr>

    <!-- CrowdDiff -->
<tr onmouseout="ff_stop()" onmouseover="ff_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ff_image'>
                <img src='images2/ddc/main_figure.png' height = "120" width="160"></div>
              <img src='images2/ddc/flow_chart.jpg' height = "100" width="160"></div>
            </div>
            <script type="text/javascript">
              function ff_start() {
                document.getElementById('ff_image').style.opacity = "1";
              }
    
              function ff_stop() {
                document.getElementById('ff_image').style.opacity = "0";
              }
              ff_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <p><a href="https://arxiv.org/pdf/2303.12790.pdf">
              <papertitle><em>CrowdDiff</em>: Multi-hypothesis Crowd Density Estimation using Diffusion Models</a></papertitle>
            
            <p>Authors : <strong>Yasiru Ranasinghe</strong>, Nithin Gopalakrishnan Nair, Wele Gedara Chaminda Bandara, and Vishal M. Patel</p> 
            <em>CVPR</em>, 2024 &nbsp <br>
              <!--<a href="https://arxiv.org/abs/2304.04745">Paper</a> /
              <a href="https://aimansnigdha.github.io/cimd/">Website</a> /
              <a href="https://github.com/aimansnigdha/Ambiguous-Medical-Image-Segmentation-using-Diffusion-Models">Code</a>-->
             
              <p>The paper proposes a novel approach to perform crowd counting with multi-hypothesis aggregation using denoising diffusion probabilistic models. The approach outperforms existing state-of-the-art methods for crowd counting.
              </p>
              </a></p>
            </td>
        </tr>

    <!-- MonoDiff -->
     
        <tr onmouseout="ff1_stop()" onmouseover="ff1_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ff1_image'>
                <img src='images2/monodiff/abstract_figure.jpg' height = "160" width="160"></div>
              <img src='images2/monodiff/pipeline.jpg' height = "100" width="160"></div>
            </div>
            <script type="text/javascript">
              function ff1_start() {
                document.getElementById('ff1_image').style.opacity = "1";
              }
    
              function ff1_stop() {
                document.getElementById('ff1_image').style.opacity = "0";
              }
              ff1_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <p><a href="https://drive.google.com/file/d/148LqyCjVPsr6WtPfhTQ3U6ESGtvPW2Ye/view?usp=drive_link">
              <papertitle><em>MonoDiff</em>: Monocular 3D Object Detection and Pose Estimation with Diffusion Models</a></papertitle>
            
            <p>Authors : <strong>Yasiru Ranasinghe</strong>, Deepti Hegde, and Vishal M. Patel</p> 
            <em>CVPR</em>, 2024 &nbsp <br>
              <!--<a href="https://arxiv.org/abs/2304.04745">Paper</a> /
              <a href="https://aimansnigdha.github.io/cimd/">Website</a> /
              <a href="https://github.com/aimansnigdha/Ambiguous-Medical-Image-Segmentation-using-Diffusion-Models">Code</a>-->
             
              <p>The paper proposes using diffusion models to perform monocular 3D object detection and pose estimation. <em>MonoDiff</em>
                does not require additional modalities to generate intermediate representations to produce box parameters.
              </p>
              </a></p>
            </td>
          </tr>

  </table>
</div>

<h2 onclick="toggleSection('preprintList')" style="cursor:pointer;">Preprints</h2>
<div id="preprintList" style="display:none;">
  <table style="width:100%;border-spacing:0;" cellpadding="20">
    <!-- RAGCC -->

            <tr onmouseout="ff8_stop()" onmouseover="ff8_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='ff8_image'>
        <img src='images2/ragcc/results.jpg' height="120" width="160" alt="Crowd Counting Results">
      </div>
      <img src='images2/ragcc/pipeline.jpg' height="100" width="160" alt="Crowd Counting Pipeline">
    </div>
    <script type="text/javascript">
      function ff8_start() {
        document.getElementById('ff8_image').style.opacity = "1";
      }
      function ff8_stop() {
        document.getElementById('ff8_image').style.opacity = "0";
      }
      ff8_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <p>
      <a href="https://drive.google.com/file/d/1IY044fXVZC0wsONiQTgG0wFNoKPVZZz6/view?usp=sharing" target="_blank">
        <papertitle><em>Enhancing Crowd Counting with Synthetic Retrieval</em></papertitle>
      </a>
    </p>
    <p>
      Authors: <strong>Yasiru Ranasinghe</strong>, and Vishal M. Patel
    </p>
    <!-- <em>Preprint</em> &nbsp;<br> -->
    <p>
      This paper proposes a retrieval-augmented framework for crowd counting that uses synthetic images and text descriptions to enrich visual embeddings. It introduces the use of non-parametric, text-guided knowledge during inference for improved generalization in zero-shot settings. The method achieves state-of-the-art performance on five benchmark datasets without relying on pseudo-labels or manual annotations.
    </p>
  </td>
</tr>

    <!-- AOD -->
    <tr onmouseout="ff10_stop()" onmouseover="ff10_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='ff10_image'>
        <img src='images2/aod/highlight.jpg' height="120" width="160" alt="Object Detection Highlight">
      </div>
      <img src='images2/aod/main.jpg' height="100" width="160" alt="Object Detection Overview">
    </div>
    <script type="text/javascript">
      function ff10_start() {
        document.getElementById('ff10_image').style.opacity = "1";
      }
      function ff10_stop() {
        document.getElementById('ff10_image').style.opacity = "0";
      }
      ff10_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <p>
      <a href="https://drive.google.com/file/d/1Ce2osRSTPy7PbdeI0ka1M3hP6Q6wCYl_/view?usp=sharing" target="_blank">
        <papertitle><em>Foundation Model Synergy for Annotator-Free Object Detection</em></papertitle>
      </a>
    </p>
    <p>
      Authors: <strong>Yasiru Ranasinghe</strong>, Celso M. de Melo, and Vishal M. Patel
    </p>
    <p>
      <!-- This work addresses the challenge of building object detectors that can identify both known and novel classes without relying on manual annotations. Unlike traditional detectors limited to closed-set detection, the proposed framework leverages foundational models—Segment Anything Model (SAM) and large vision-language models (VLMs)—to autonomously generate and semantically label object proposals. The pipeline supports adaptation to unknown environments and domain-specific conditions in real time. Experiments show substantial performance gains, including a 25.6% mAP improvement on both COCO and LVIS compared to GroundingDINO, demonstrating the framework's scalability and potential to eliminate annotation costs. -->
      Proposes an annotator-free object detection framework using foundational models—SAM and vision-language models (VLMs)—to autonomously generate and label object proposals. The pipeline adapts in real time to novel and domain-specific environments, eliminating the need for manual annotations while achieving strong performance across standard benchmarks.
    </p>
  </td>
</tr>


<tr onmouseout="ff11_stop()" onmouseover="ff11_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
      <div class="two" id='ff11_image'>
        <img src='images2/ebt/main.jpg' height="120" width="160" alt="ET-Barlow Twins Results">
      </div>
      <img src='images2/ebt/main.jpg' height="100" width="160" alt="ET-Barlow Twins Overview">
    </div>
    <script type="text/javascript">
      function ff11_start() {
        document.getElementById('ff11_image').style.opacity = "1";
      }
      function ff11_stop() {
        document.getElementById('ff11_image').style.opacity = "0";
      }
      ff11_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <p>
      <a href="https://drive.google.com/file/d/10Mf_dfWq5GOg1104yxf9bIHaasLGAjgk/view?usp=sharing" target="_blank">
        <papertitle><em>Eigen-Target Decorrelation for Robust Self-Supervised Learning</em></papertitle>
      </a>
    </p>
    <p>
      Authors: <strong>Yasiru Ranasinghe</strong> and Vishal M. Patel
    </p>
    <p>
      <!-- This paper introduces ET-Barlow Twins, a self-supervised learning framework that improves upon Barlow Twins by addressing its training instabilities and overfitting risks. The method replaces the identity target with a data-driven eigen-target derived from the top-N singular vectors of the correlation matrix. A student-teacher design stabilizes optimization by using the teacher's global view statistics to guide the student's alignment via augmented views. Theoretical analysis and empirical results demonstrate tighter optimization and superior generalization, with ET-Barlow Twins outperforming Barlow Twins and other leading SSL approaches across multiple benchmarks. -->
      Introduces ET-Barlow Twins, a self-supervised learning approach that replaces the identity target with a data-adaptive eigen-target from top-N singular vectors. A student-teacher framework ensures stable training by aligning cross-view correlations. The method improves optimization robustness and generalization over standard Barlow Twins and other SSL baselines.
    </p>
  </td>
</tr>



  </table>
</div>

<h2 onclick="toggleSection('confList')" style="cursor:pointer;">Conferences</h2>
<div id="confList" style="display:none;">
  <table style="width:100%;border-spacing:0;" cellpadding="20">
    <!-- AVSS Paper -->
        <tr onmouseout="ff6_stop()" onmouseover="ff6_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                <div class="two" id='ff6_image'>
                    <img src='images2/lvlm/headline.jpg' height="120" width="160" alt="LVLM headline">
                </div>
                <img src='images2/lvlm/pipeline.jpg' height="100" width="160" alt="LVLM pipeline">
                </div>
                <script type="text/javascript">
                function ff6_start() {
                    document.getElementById('ff6_image').style.opacity = "1";
                }
                function ff6_stop() {
                    document.getElementById('ff6_image').style.opacity = "0";
                }
                ff6_stop()
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <p>
                <a href="https://drive.google.com/file/d/1fkpjtXnevX2CiJA6qEPNFnysLHLr7Ef5/view?usp=sharing" target="_blank">
                    <papertitle><em>Zero-Shot Scene Understanding for Automatic Target Recognition Using Large Vision-Language Models</em></papertitle>
                </a>
                </p>
                <p>
                Authors: <strong>Yasiru Ranasinghe</strong>, Vibashan VS, James Uplinger, Celso De Melo, and Vishal M. Patel
                </p>
                <em>AVSS</em>, 2025 &nbsp;<br>
                <p>
                This work presents a robust pipeline for zero-shot automatic target recognition by combining the localization power of open-world detectors with the recognition abilities of large vision-language models (LVLMs). It evaluates multiple LVLMs on military vehicles under challenging conditions and highlights strategies for reliable recognition in novel domains.
                </p>
            </td>
          </tr>

    <!-- FG Paper -->
        <tr onmouseout="ff0_stop()" onmouseover="ff0_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ff0_image'>
                <img src='images2/crowdloc/image1.png' height = "120" width="160"></div>
              <img src='images2/crowdloc/image2.png' height = "32" width="160"></div>
            </div>
            <script type="text/javascript">
              function ff0_start() {
                document.getElementById('ff0_image').style.opacity = "1";
              }
    
              function ff0_stop() {
                document.getElementById('ff0_image').style.opacity = "0";
              }
              ff0_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <p><a href="https://drive.google.com/file/d/1nhNYMJ9XFatDRVcedLiEF6Ue-VjzVGDe/view?usp=drive_link">
              <papertitle>Crowd Detection via Point Localization with Diffusion Models</a></papertitle>
            
            <p>Authors : <strong>Yasiru Ranasinghe</strong>, and Vishal M. Patel</p> 
            <em>IEEE FG</em>, 2024 &nbsp <br>
              <!--<a href="https://arxiv.org/abs/2304.04745">Paper</a> /
              <a href="https://aimansnigdha.github.io/cimd/">Website</a> /
              <a href="https://github.com/aimansnigdha/Ambiguous-Medical-Image-Segmentation-using-Diffusion-Models">Code</a>-->
             
              <p>The paper proposes using diffusion models to localize crowd in images and count the number of people in a scene.
                The proposed method generates the head locations as a generative task without a separate detector for point proposals.
              </p>
              </a></p>
            </td>
          </tr>

          <!-- ICIIS 2020 -->
	    <tr onmouseout="ff3_stop()" onmouseover="ff3_start()">
          <td style="padding:20px;width:25%;vertical-align:top">
            <div class="one">
              <div class="two" id='ff3_image'>
                <img src='images2/iciis_2020/results.png' height="180" width="160"></div>
              <img src='images2/iciis_2020/main_figure.png' height="100" width="160">
            </div>
            <script type="text/javascript">
              function ff3_start() {
                document.getElementById('ff3_image').style.opacity = "1";
              }
    
              function ff3_stop() {
                document.getElementById('ff3_image').style.opacity = "0";
              }
              ff3_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:top">
            
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9342727">
              <papertitle>Convolutional Autoencoder for Blind Hyperspectrl Unmixing</a></papertitle>
            
              <p>Authors : <strong>Yasiru Ranasinghe</strong>, Sanjaya Herath, Kavinga Weerasooriya, Mevan Ekanayake, Roshan Godaliyadda, Parakrama Ekanayake, and Vijitha Herath</p> 
            <em>IEEE International Conference on Industrial and Information Systems</em>, 2020 &nbsp <br>
             
              <p>
              The paper process a convolutional autoencoder to realize the nonnegative matrix factorization using deep learning architectures. The proposed methods is applied to extract endmembers and abundances of hyperspectral remote sensing data. The proposed method produced state-of-the-art results on abundance estimation and competitive results in terms of endmember extraction.
              </p>
              <p></p>
              </a></p>
            </td>
          </tr>
        
        <!-- ICIIS 2019 -->
        <tr onmouseout="ff4_stop()" onmouseover="ff4_start()">
          <td style="padding:20px;width:25%;vertical-align:top">
            <div class="one">
              <div class="two" id='ff4_image'>
                <img src='images2/iciis_2019/results.png' height="200" width="160"></div>
              <img src='images2/iciis_2019/main_figure.png' height="160" width="160">
            </div>
            <script type="text/javascript">
              function ff4_start() {
                document.getElementById('ff4_image').style.opacity = "1";
              }
    
              function ff4_stop() {
                document.getElementById('ff4_image').style.opacity = "0";
              }
              ff4_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:top">
            
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9063280">
              <papertitle>Hyperspectral Imaging Based Method to Identify Potential Limestone Deposis</a></papertitle>
            
              <p>Authors : <strong>DYL Ranasinghe</strong>, HMS Lakmal, HMHK Weerasooriya, EMMB Ekanayake, GMRI Godaliyadda, HMVR Herath, and MPB Ekanayake</p> 
            <em>IEEE International Conference on Industrial and Information Systems</em>, 2019 &nbsp <br>
             
              <p>
              The paper proposed an algorithm to determine the availability of surface limestone using hyperspectral satellite imagery of an area. We incorporate traditional image and signal processing, and statistical data analysis techniques in the algorithm. Further, we generated a self-supervisied representation for the hyperspectral signature of limestone in the absence of a groundtruth to improve classification accuracy and spatial continuity of the probability map.
              </p>
              <p></p>
              </a></p>
            </td>
          </tr>

  </table>
</div>

<h2 onclick="toggleSection('journalList')" style="cursor:pointer;">Journals</h2>
<div id="journalList" style="display:none;">
  <table style="width:100%;border-spacing:0;" cellpadding="20">
    <!-- IEEE Access -->
        <tr onmouseout="ff2_stop()" onmouseover="ff2_start()">
            <td style="padding:20px;width:25%;vertical-align:top">
              <div class="one">
                <div class="two" id='ff2_image'>
                  <img src='images2/access/results.png' height="90" width="160"></div>
                <img src='images2/access/main_figure.png' height="80" width="160">
              </div>
              <script type="text/javascript">
                function ff2_start() {
                  document.getElementById('ff2_image').style.opacity = "1";
                }
      
                function ff2_stop() {
                  document.getElementById('ff2_image').style.opacity = "0";
                }
                ff2_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:top">
              	
              	<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9686744">
                <papertitle>Transmittance Multispectral Imaging for Reheated Coconut Oil Differentiation</a></papertitle>
              
                <p>Authors : <strong>DYL Ranasinghe </strong>, HK Weerasooriya, S Herath, MP Bandara Ekanayake, HMVR Herath, GMRI Godaliyadda, and Terrence Madhujith</p> 
              <em>IEEE Access</em>, 2022 &nbsp <br>
               
                <p>The article process a novel non invasive method for food quality analysis, specifically in terms of adulteration, using multispectral images and statistical signal processing and image processing. The proposed method yielded statistically significant results and with significant practical implications.</p>
                <p></p>
                </a></p>
              </td>
            </tr>
     

    <!-- IEEE JSTARS -->
        <tr onmouseout="ff5_stop()" onmouseover="ff5_start()">
          <td style="padding:20px;width:25%;vertical-align:top">
            <div class="one">
              <div class="two" id='ff5_image'>
                <img src='images2/jstars/algorithm.png' height="180" width="160"></div>
              <img src='images2/jstars/main_figure.png' height="100" width="160">
            </div>
            <script type="text/javascript">
              function ff5_start() {
                document.getElementById('ff5_image').style.opacity = "1";
              }
    
              function ff5_stop() {
                document.getElementById('ff5_image').style.opacity = "0";
              }
              ff5_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:top">
            
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9609564">
              <papertitle>Constrained Nonnegative Matrix Factorization for Blind Hyperspectral Unmixing Incorporating Endmember Independence</a></papertitle>
            
              <p>Authors : EMMB Ekanayake, HMHK Weerasooriya, <strong>DYL Ranasinghe </strong>, S Herath, B Rathnayake, GMRI Godaliyadda, MPB Ekanayake, and HMVR Herath</p> 
            <em>IEEE Journal of Seleted Topics in Applied Earth Observation and Remote Sensing</em>, 2021 &nbsp <br>
             
              <p>
              The paper proposes a novel algorithm to extract endmembers and abundances of hyperspectral remote sensing data. We introduced a regularizer for the nonnegative matrix factorization which improves independence of endmember statistics. The algorithm illustrated superior performance interms of endmber extraction from hyperspectral data.
              </p>
              <p></p>
              </a></p>
            </td>
          </tr>
     
  </table>
</div>

<script>
  function toggleSection(id) {
    const section = document.getElementById(id);
    section.style.display = section.style.display === "block" ? "none" : "block";
  }
</script>


        <hr>
        <p style="text-align:right;font-size:small;">
          Template taken from <a href="https://github.com/jonbarron/jonbarron_website">here</a>. Last updated October 2023.
        </p>
      </td>
    </tr>
  </table>
</body>
</html>
