<!DOCTYPE HTML>
<html lang="bn"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Yasiru Ranasinghe</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/sloth.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yasiru Ranasinghe</name>
              </p>
              <p>

                I am a 2nd year Ph.D. candidate at <a href="https://engineering.jhu.edu/vpatel36/">Vision & Image Understanding Lab</a>, <a href="https://www.jhu.edu/">Johns Hopkins University</a>  under the supervision of <a href="https://scholar.google.com/citations?user=AkEXTbIAAAAJ&hl=en">Dr. Vishal M. Patel</a>.  My research focuses on computer vision and its application in the medical field, with specific emphasis on image/3D segmentation, generative models, and representation learning. </p>
                <p>
Prior to pursuing my doctoral studies, I served as a research assistant at my undergraduate school <a href="http://northsouth.edu/">North South University</a>, Dhaka, Bangladesh, where I worked on computer vision with applications in medical imaging under the supervision of <a href="https://msrahman.buet.ac.bd/">Dr. M. Sohel Rahman</a> and <a href="https://scholar.google.com/citations?user=PxNOguMAAAAJ&hl=en">Dr. Mahdy Rahman Chowdhury</a>. I've also worked as a research assistant at <a href="https://scholar.google.com/citations?user=8yRdePEAAAAJ&hl=en">the Center for Applied Scientific Computing</a> under the supervision of <a href="https://scholar.google.com/citations?user=8yRdePEAAAAJ&hl=en">Dr. Mamun Molla</a>.
              </p>


              <p style="text-align:center">
                <a href="mailto:aimon.rahman@northsouth.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=h52EUGcAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/aimon-rahman-1a4021191/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://publons.com/researcher/3763362/aiman-rahman/">Publons</a>
                
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/aiman.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/aiman.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <hr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">

              <heading>Research</heading>
              <p>
                My research lies at the intersection of computer vision and medical image analysis, with a focus on developing deep learning techniques to make healthcare more affordable and accessible globally.

                My specific research interests include 2D/3D segmentations, generative networks, representation learning, and addressing bias/ambiguity in medical image problems. I am also open to exploring general vision problems, particularly in the areas of generative networks and representation learning.
                
                I have a strong track record of first-author publications in leading conferences, such as MICCAI and CVPR. Additionally, I am committed to mentoring undergraduate student research groups in machine learning at NSU.

              </p>
            </td>
          </tr>
        </tbody></table>

        
        <hr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              <div style="width:100%;overflow-y:scroll; height:200px;">
              <ul>
                
                <li><b>February, 2023:</b> One Paper accepted in <b>CVPR 2023.</b> </li>
                <li><b>June, 2022:</b> Received <b>MICCAI Student Travel Award.</b> </li>
                <li><b>June, 2022:</b> Two Papers accepted at <b>MICCAI 2022.</b> </li>
                <li><b>September, 2021:</b> Joined as a PhD student at <b>VIU Lab, Johns Hopkins University.</b> </li>
                <li><b>December, 2020:</b> One Paper is Accepted at <b>Tissue and Cell.</b></li>
                <li><b>September, 2020:</b> One Paper is Accepted at <b>IJMPC.</b></li>
                <li><b>July, 2020:</b> One Paper is Accepted at <b>PRIME MICCAI 2020.</b>  </li>
                <li><b>November, 2019:</b> One Paper is Accepted at <b>ICME 2019.</b></li>
                <li> <b>September, 2019:</b> One Paper is Accepted at <b>IEEE MoRSE 2019</b>. </li>
              </ul>
              </div>

            </p>
          </td>
        </tr>
      </tbody></table>


        <table width="100%" align="center" border="0" cellpadding="0"><tbody>
          <hr>
        <heading>Selected Publications</heading>
<p>See my <a href="https://scholar.google.com/citations?hl=en&user=h52EUGcAAAAJ">Google Scholar</a> profile for the complete and most recent publications.</p>
        

       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

        <tr onmouseout="ff_stop()" onmouseover="ff_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ff_image'>
                <img src='images/amb_2.jpg' height = "100" width="160"></div>
              <img src='images/amb_1.jpg' height = "100" width="160">
            </div>
            <script type="text/javascript">
              function ff_start() {
                document.getElementById('ff_image').style.opacity = "1";
              }
    
              function ff_stop() {
                document.getElementById('ff_image').style.opacity = "0";
              }
              ff_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <p><a href="https://arxiv.org/abs/2304.04745">
              <papertitle>Ambiguous Medical Image Segmentation using Diffusion Models</a></papertitle>
            
            <p>Authors : <strong>Aimon Rahman </strong>,  Jeya Maria Jose Valanarasu, Ilker Hacihaliloglu, Vishal M Patel</p> 
            <em>CVPR</em>, 2023 &nbsp <br>
              <a href="https://arxiv.org/abs/2304.04745">Paper</a> /
              <a href="https://aimansnigdha.github.io/cimd/">Website</a> /
              <a href="https://github.com/aimansnigdha/Ambiguous-Medical-Image-Segmentation-using-Diffusion-Models">Code</a>
             
              <p>The paper proposes a new approach for medical image segmentation that utilizes expert groups to generate multiple plausible outputs. The approach outperforms existing state-of-the-art networks in accuracy and diversity. The authors also introduce a new metric aligned with clinical practice</p>
              <p></p>
              </a></p>
            </td>
          </tr>


        <tr onmouseout="ff1_stop()" onmouseover="ff1_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ff1_image'>
                <img src='images/O_gcn_1.jpg' height="100" width="160"></div>
              <img src='images/O_gcn_1.jpg' height="100" width="160">
            </div>
            <script type="text/javascript">
              function ff1_start() {
                document.getElementById('ff1_image').style.opacity = "1";
              }
    
              function ff1_stop() {
                document.getElementById('ff1_image').style.opacity = "0";
              }
              ff1_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            
              <papertitle>Orientation-Guided Graph Convolutional Network for Bone Surface Segmentation</papertitle>
            
              <p>Authors : <strong>Aimon Rahman </strong>, WGC Bandara, Jeya Maria Jose Valanarasu, Ilker Hacihaliloglu, Vishal M Patel</p> 
            <em>MICCAI</em>, 2022 &nbsp <br>
             
              <p>The article proposes a new method for bone surface segmentation using an orientation-guided graph convolutional network to improve connectivity in ultrasound images. The approach also adds supervision on the orientation of the bone surface to further impose connectivity. Validation on over 1000 in vivo US scans shows a 5.01% improvement over state-of-the-art methods in connectivity metric.</p>
              <p></p>
              </a></p>
            </td>
          </tr>




          <tr onmouseout="ff2_stop()" onmouseover="ff2_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff2_image'>
                  <img src='images/network.jpg' height="100" width="160"></div>
                <img src='images/network.jpg' height="100" width="160">
              </div>
              <script type="text/javascript">
                function ff2_start() {
                  document.getElementById('ff1_image').style.opacity = "1";
                }
      
                function ff2_stop() {
                  document.getElementById('ff1_image').style.opacity = "0";
                }
                ff2_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle>Simultaneous Bone and Shadow Segmentation Network Using Task Correspondence Consistency</papertitle>
              
                <p>Authors : <strong>Aimon Rahman </strong>, Jeya Maria Jose Valanarasu, Ilker Hacihaliloglu, Vishal M Patel</p> 
              <em>MICCAI</em>, 2022 &nbsp <br>
               
                <p>The article proposes a new approach for segmenting both bone surface and the corresponding acoustic shadow in ultrasound images using a single end-to-end network with a shared transformer-based encoder and task independent decoders. The approach leverages the complementary features between the two tasks and includes a cross-task feature transfer block to learn meaningful feature transfer between the two decoders.</p>
                <p></p>
                </a></p>
              </td>
            </tr>






    
          <tr onmouseout="fh_stop()" onmouseover="fh_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='fh_image'>
                  <img src='images/fh-after.PNG' width="160"></div>
                <img src='images/fh-before.PNG' width="160">
              </div>
              <script type="text/javascript">
                function fh_start() {
                  document.getElementById('fh_image').style.opacity = "1";
                }
      
                function fh_stop() {
                  document.getElementById('fh_image').style.opacity = "0";
                }
                fh_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                              <papertitle>3C-GAN: class-consistent CycleGAN for malaria domain adaptation model</papertitle>
              
              <p>Authors : <strong>Aimon Rahman </strong>, M Sohel Rahman, M.R.C. Mahdy</p> 
              <em>Biomedical Physics & Engineering Express</em>, 2021 &nbsp <br>
               
                <p>We introduce a modified loss function in unpaired adversarial translation model to prevent unwanted feature hallucination.</p>
                <p></p>
                </a></p>
              </td>
            </tr>


            <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
            <td width="25%">
              <div class="one">
                <div class="two" id = 'jump_image'><img src='images/clef2021.png'></div>
                <img src='images/clef2021.png'>
              </div>
              <script type="text/javascript">
                function jump_start() {
                  document.getElementById('jump_image').style.opacity = "1";
                }
                function jump_stop() {
                  document.getElementById('jump_image').style.opacity = "0";
                }
                jump_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <p><a href="http://ceur-ws.org/Vol-2936/paper-121.pdf">
              <papertitle>ViPTT-Net: Video pretraining of spatio-temporal model for tuberculosis type classification from chest CT scans</papertitle></a><br>
              Authors : Hasib Zunair, <strong>Aimon Rahman </strong>, and Nabeel Mohammed<br> 
              <em>Conference and Labs of the Evaluation Forum (CLEF)</em>, 2021<br>
              </p>
              <a href="https://arxiv.org/abs/2105.12810">Paper</a> / 
              <a href="https://github.com/hasibzunair/viptt-net">Code</a> /
              <a href="https://www.aicrowd.com/challenges/imageclef-2021-tuberculosis-tbt-classification/leaderboards">Leaderboard <font color="red">(2nd place)</font></a>
    
                <p>We pretrain a model on videos for human activity recognition which leads to better 
                  representations for the downstream tuberculosis type classification task, especially for under-represented class samples. 
                  Our method achieved 2nd place in the <a href="https://www.imageclef.org/2021/medical/tuberculosis"> ImageCLEF 2021
                    Tuberculosis Type Classification Challenge.</a></p>
                <p></p>
                </a></p>
              </td>
            </tr>



            
            <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
            <td width="25%">
              <div class="one">
                <div class="two" id = 'jump_image'><img src='images/tissueandcell2.png'></div>
                <img src='images/tissueandcell2.png'>
              </div>
              <script type="text/javascript">
                function jump_start() {
                  document.getElementById('jump_image').style.opacity = "1";
                }
                function jump_stop() {
                  document.getElementById('jump_image').style.opacity = "0";
                }
                jump_stop()
              </script>
            </td>
            <td valign="top" width="75%">
              <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0040816621001695">
              <papertitle>Automatic segmentation of blood cells from microscopic slides: A comparative analysis</papertitle></a><br>
              Authors : Deponker Sarker Depto, Shazidur Rahman, Md. Mekayel Hosen, Mst Shapna Akter, 
              Tamanna Rahman Reme, <strong>Aimon Rahman</strong>, M Sohel Rahman, M.R.C.Mahdy<br> 
              <em>Tissue and Cell</em>, 2021</p>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S0040816621001695">Paper</a> /
              <a href="https://github.com/Deponker/Blood-cell-segmentation-dataset">Dataset</a> /
              <a href="https://github.com/Deponker/Blood-cell-segmentation">Code</a>
               
                <p>
    
                This work proposes a blood cell segmentation dataset consisting of multiple cell types. 
                Additionally, all cell types 
                do not have equal instances, which encourages researchers to develop algorithms for 
                learning from imbalanced classes in a few shot learning paradigm. We also provide both learning and non-learning based
                methods as baselines.
    
                </p>
                <p></p>
                </a></p>
              </td>
            </tr>




    
    
            <tr onmouseout="thresh_stop()" onmouseover="thresh_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='thresh_image'>
                    <img src='images/data-before.PNG' width="160"></div>
                  <img src='images/data-after.PNG' width="160">
                </div>
                <script type="text/javascript">
                  function thresh_start() {
                    document.getElementById('thresh_image').style.opacity = "1";
                  }
    
                  function thresh_stop() {
                    document.getElementById('thresh_image').style.opacity = "0";
                  }
                  thresh_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>A Comparative Analysis of Deep Learning Architectures on High Variation Malaria Parasite Classification Dataset</papertitle>
                
                <p>Authors : <strong>Aimon Rahman </strong>, Hasib Zunair, Tamanna Rahman Reme, M Sohel Rahman, M.R.C. Mahdy</p> 
                <em>Tissue and Cell</em>, 2020 &nbsp <br>
              
                  <p>Transformed an object detection dataset to classification dataset, conditional image synthesis is used to generate synthetic dataset and benchmarked several classification algorithms for the task of detecting malaria from microscopic images of red blood cells.  </p>
                  <p></p>
                  </a></p>
                </td>
              </tr>














      


        <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
        <td width="25%">
          <div class="one">
            <div class="two" id = 'jump_image'><img src='images/PRIME-MICCAI2020.jpg'></div>
            <img src='images/PRIME-MICCAI2020.jpg'>
          </div>
          <script type="text/javascript">
            function jump_start() {
              document.getElementById('jump_image').style.opacity = "1";
            }
            function jump_stop() {
              document.getElementById('jump_image').style.opacity = "0";
            }
            jump_stop()
          </script>
        </td>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/abs/2007.13224">
          <papertitle>Uniformizing Techniques to Process CT scans with 3D CNNs for Tuberculosis Prediction</papertitle></a></p>
          <p>Authors : Hasib Zunair, <strong>Aimon Rahman</strong>, Nabeel Mohammed, and Joseph Paul Cohen</p> 
          <em>PRedictive Intelligence In MEdicine (PRIME), Medical Image Computing & Computer Assisted Intervention (MICCAI)</em>, 2020<br>
          <a href="https://arxiv.org/abs/2007.13224">Paper</a> / <a href="https://github.com/hasibzunair/uniformizing-3D">Code</a> / <a href="https://docs.google.com/presentation/d/1k33muekl3RkJWR5ZdbVo6Sgs8R9O3th3r07_oRMCHfo/edit?usp=sharing">Slides</a>

            <p>Showed that analyzing 3D medical images in a per slice basis is a sub-optimal approach, that can be improved by 3D context. Ranked 5-th in <a href="https://www.imageclef.org/2019/medical/tuberculosis"> ImageCLEF 2019</a>.</p>
            <p></p>
            </a></p>
          </td>
        </tr>



     



      





        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
          <td width="25%">
            <div class="one">
              <div class="two" id = 'jump_image'><img src='images/malariadetection2019.png'></div>
              <img src='images/malariadetection2019.png'>
            </div>
            <script type="text/javascript">
              function jump_start() {
                document.getElementById('jump_image').style.opacity = "1";
              }
              function jump_stop() {
                document.getElementById('jump_image').style.opacity = "0";
              }
              jump_stop()
            </script>
          </td>
          <td valign="top" width="75%">
            <p><a href="https://arxiv.org/abs/1907.10418">
            <papertitle>Improving Malaria Parasite Detection from Red Blood Cell using Deep Convolutional Neural Networks</papertitle></a></p>
            <p>Authors : <strong>Aimon Rahman </strong>, Hasib Zunair, M Sohel Rahman, Jesia Quader Yuki, Sabyasachi Biswas, Md Ashraful Alam, Nabila Binte Alam, M.R.C. Mahdy</p> 
            <em>arXiv</em>, 2019<br>
            <a href="https://arxiv.org/abs/1907.10418">Paper</a> / <a href="https://github.com/hasibzunair/malaria-detection">Code</a> 
             
              <p>Benchmarked several classification algorithms for the task of detecting malaria from microscopic images of red blood cells. Transfer learning approach worked best in our study.</p>
              <p></p>
              </a></p>
            </td>
          </tr>

          
      <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
        <div class="two" id = 'aperture_image'><img src='images/fastmri2019.png'></div>
        <img src='images/fastmri2019.png'>
        </div>
        <script type="text/javascript">
        function aperture_start() {
        document.getElementById('aperture_image').style.opacity = "1";
        }
        function aperture_stop() {
        document.getElementById('aperture_image').style.opacity = "0";
        }
        aperture_stop()
        </script>
      </td>
      <td valign="top" width="75%">
          <p><a href="https://fastmri.org/leaderboards/challenge/2019/">
            <papertitle>Res-U-Net architecture for reconstruction of high resolution knee MRI scans</papertitle></a></p>
     <p>Authors: Hasib Zunair, <strong>Aimon Rahman</strong> </p>
     <em>fastMRI Image Reconstruction Challenge (Single coil track), Facebook AI Research</em>, 2019<br>
        <a href="https://github.com/hasibzunair/res-unet-fastmri">Code</a>
        <p></p>
        <p> Trained a U-Net architecture with a pretrained ResNet backbone on knee MRIs at the slice level. The goal was to reconstruct high resolution images from the given undersampled image.
        </p>
      </td>
    </tr>


    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" ></tr>
      <td width="25%">
        <div class="one">
        <div class="two" id = 'aperture_image'><img src='images/imageclef2019.jpg'></div>
        <img src='images/imageclef2019.jpg'>
        </div>
        <script type="text/javascript">
        function aperture_start() {
        document.getElementById('aperture_image').style.opacity = "1";
        }
        function aperture_stop() {
        document.getElementById('aperture_image').style.opacity = "0";
        }
        aperture_stop()
        </script>
      </td>
      <td valign="top" width="75%">
          <p><a href="http://www.dei.unipd.it/~ferro/CLEF-WN-Drafts/CLEF2019/paper_77.pdf">
            <papertitle>Estimating Severity from CT Scans of Tuberculosis Patients using 3D Convolutional Nets</papertitle></a></p>
     <p>Authors: Hasib Zunair, <strong>Aimon Rahman </strong>, Nabeel Mohammed</p>
     <em>CLEF Working Notes - Conference and Labs of the Evaluation Forum</em>, 2019<br>
        <a href="https://www.researchgate.net/publication/334680379_Estimating_Severity_from_CT_Scans_of_Tuberculosis_Patients_using_3D_Convolutional_Nets_and_Slice_Selection">Paper</a> / <a href="https://github.com/hasibzunair/tuberculosis-severity">Code</a>
        <p></p>
        <p>A 3D CNN with a slice selection method employed in the task of chest CT image analysis
          for predicting tuberculosis (TB). Our method achieved 10-th place in the <a href="https://www.imageclef.org/2019/medical/tuberculosis"> ImageCLEF 2019
            Tuberculosis SVR - Severity scoring</a>.
        </p>
      </td>
    </tr>



    
         
         
        </tbody></table>

        <hr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Template taken from <a href="https://github.com/jonbarron/jonbarron_website">here</a>. Last updated March 2023.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>



</body>

</html>
